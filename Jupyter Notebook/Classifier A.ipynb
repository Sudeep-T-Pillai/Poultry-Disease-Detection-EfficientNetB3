{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use This Notebook: Poultry Disease Classifier (EfficientNet-B3)\n",
    "\n",
    "This notebook trains an EfficientNet-B3 model for poultry disease image classification using a two-stage fine-tuning approach.\n",
    "\n",
    "## 1. Prerequisites\n",
    "\n",
    "*   Python environment with Jupyter support (Google Colab, Kaggle, local).\n",
    "*   GPU recommended for faster training.\n",
    "*   Kaggle account/API key for dataset download (if running locally or on Colab without native Kaggle integration).\n",
    "\n",
    "## 2. Setup\n",
    "\n",
    "Run the initial cells in order:\n",
    "\n",
    "1.  **Download Dataset:** Fetches the dataset zip file from Kaggle.\n",
    "2.  **Unzip Dataset:** Extracts images into the `/content/poultry-diseases` directory.\n",
    "3.  **Install Dependencies:** Installs `torch`, `torchvision`, `efficientnet_pytorch`, and `thop`.\n",
    "4.  **Import Libraries:** Loads necessary Python packages.\n",
    "\n",
    "## 3. Configuration & Data Preparation\n",
    "\n",
    "1.  **Model Setup:** Loads a pre-trained EfficientNet-B3 and adapts its final layer for 4 classes.\n",
    "2.  **Data Transformations:** Defines image resizing, augmentation (for training), and normalization.\n",
    "3.  **Dataset Loading & Sampling:**\n",
    "    *   **CRITICAL:** Update the paths in the `ImageFolder` calls to point to your *actual* `train` and `test` directories (e.g., `/content/poultry-diseases/data/data/train`).\n",
    "    *   The code samples 10,000 images per class for training (`train_subset`) and a proportionally sampled validation set (`val_subset`).\n",
    "4.  **DataLoaders:** Prepares data batches for training and validation. Adjust `batch_size` based on your GPU memory.\n",
    "\n",
    "## 4. Model Training (Two Stages)\n",
    "\n",
    "1.  **Stage 1 (Classifier Only):**\n",
    "    *   Freezes base model layers, trains only the final classifier for 17 epochs.\n",
    "    *   Run the cell under the \"Stage 1\" comment.\n",
    "2.  **Stage 2 (Full Model):**\n",
    "    *   Unfreezes all layers, fine-tunes the entire model for 10 epochs with a lower learning rate.\n",
    "    *   Saves the model weights (`best_model.pth`) whenever validation accuracy improves.\n",
    "    *   Run the cell under the \"Stage 2\" comment.\n",
    "\n",
    "**Note on Iterations:** The code executes *one* full training run (Stage 1 + Stage 2). The final markdown log shows results from *three* such iterations, which would require re-running the sampling and training cells, potentially with adjustments.\n",
    "\n",
    "## 5. Evaluation and Analysis\n",
    "\n",
    "After training, run the subsequent cells:\n",
    "\n",
    "1.  **Load Best Model:** Loads the saved `best_model.pth`.\n",
    "2.  **Calculate Metrics:** Computes and prints F1 scores (macro, weighted), mAP, per-class precision/recall/F1, and the confusion matrix using the validation subset. Ensure `class_names` match your dataset folders.\n",
    "3.  **Calculate FLOPs:** Estimates the total computational cost (TeraFLOPs) for the entire training process (both stages across multiple iterations, as configured in the cell).\n",
    "4.  **Calculate Inference Speed:** Measures the average time to classify a single image.\n",
    "\n",
    "## 6. Interpreting Results\n",
    "\n",
    "*   **Accuracy/Loss:** Monitor trends during training.\n",
    "*   **F1/mAP/Per-Class:** Assess detailed performance, especially for imbalanced classes.\n",
    "*   **Confusion Matrix:** Identify specific class confusions.\n",
    "*   **FLOPs/Inference Speed:** Gauge model efficiency and prediction speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o /content/poultry-diseases.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/chandrashekarnatesh/poultry-diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip poultry-diseases.zip -d /content/poultry-diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:45:09.832560Z",
     "iopub.status.busy": "2025-04-08T09:45:09.832222Z",
     "iopub.status.idle": "2025-04-08T09:45:20.335514Z",
     "shell.execute_reply": "2025-04-08T09:45:20.334383Z",
     "shell.execute_reply.started": "2025-04-08T09:45:09.832535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision efficientnet_pytorch\n",
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:45:28.787025Z",
     "iopub.status.busy": "2025-04-08T09:45:28.786681Z",
     "iopub.status.idle": "2025-04-08T09:45:33.578066Z",
     "shell.execute_reply": "2025-04-08T09:45:33.577267Z",
     "shell.execute_reply.started": "2025-04-08T09:45:28.786998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, average_precision_score, confusion_matrix\n",
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:45:58.954019Z",
     "iopub.status.busy": "2025-04-08T09:45:58.953566Z",
     "iopub.status.idle": "2025-04-08T09:46:00.466710Z",
     "shell.execute_reply": "2025-04-08T09:46:00.465815Z",
     "shell.execute_reply.started": "2025-04-08T09:45:58.953994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pre-trained EfficientNet B3\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:46:07.443093Z",
     "iopub.status.busy": "2025-04-08T09:46:07.442813Z",
     "iopub.status.idle": "2025-04-08T09:46:07.447434Z",
     "shell.execute_reply": "2025-04-08T09:46:07.446729Z",
     "shell.execute_reply.started": "2025-04-08T09:46:07.443072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modify the classifier\n",
    "num_classes = 4\n",
    "model._fc = nn.Linear(model._fc.in_features, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:46:40.813506Z",
     "iopub.status.busy": "2025-04-08T09:46:40.813167Z",
     "iopub.status.idle": "2025-04-08T09:46:40.818127Z",
     "shell.execute_reply": "2025-04-08T09:46:40.817290Z",
     "shell.execute_reply.started": "2025-04-08T09:46:40.813471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data transformations for training dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),              # Resize images to 300x300 pixels\n",
    "    transforms.RandomHorizontalFlip(),          # Randomly flip images horizontally for data augmentation\n",
    "    transforms.ToTensor(),                      # Convert images to PyTorch tensors (C x H x W format)\n",
    "    transforms.Normalize(                       # Normalize pixel values using ImageNet mean and std\n",
    "        mean=[0.485, 0.456, 0.406],            # Mean for RGB channels\n",
    "        std=[0.229, 0.224, 0.225]              # Standard deviation for RGB channels\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Data transformations for validation dataset\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),              # Resize images to 300x300 pixels\n",
    "    transforms.ToTensor(),                      # Convert images to PyTorch tensors (C x H x W format)\n",
    "    transforms.Normalize(                       # Normalize pixel values using ImageNet mean and std\n",
    "        mean=[0.485, 0.456, 0.406],            # Mean for RGB channels\n",
    "        std=[0.229, 0.224, 0.225]              # Standard deviation for RGB channels\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:46:45.500034Z",
     "iopub.status.busy": "2025-04-08T09:46:45.499688Z",
     "iopub.status.idle": "2025-04-08T09:55:59.826824Z",
     "shell.execute_reply": "2025-04-08T09:55:59.825862Z",
     "shell.execute_reply.started": "2025-04-08T09:46:45.500007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the number of classes in the dataset\n",
    "num_classes = 4  # Poultry disease dataset has 4 distinct classes\n",
    "\n",
    "# Initialize training dataset\n",
    "# ImageFolder loads images from the specified directory, applying train_transform\n",
    "train_dataset = ImageFolder(root='path_to/poultry-diseases/data/data/train', transform=train_transform)\n",
    "\n",
    "# Initialize validation dataset\n",
    "# ImageFolder loads images from the specified directory, applying val_transform\n",
    "val_dataset = ImageFolder(root='path_to/poultry-diseases/data/data/test', transform=val_transform)\n",
    "\n",
    "# Get training dataset details\n",
    "train_targets = train_dataset.targets  # Extract list of class labels for training images\n",
    "# Create dictionary mapping each class index to indices of images belonging to that class\n",
    "train_class_indices = {\n",
    "    class_idx: [i for i, t in enumerate(train_targets) if t == class_idx]\n",
    "    for class_idx in range(num_classes)\n",
    "}\n",
    "# Calculate number of training images per class\n",
    "T_per_class = [len(train_class_indices[class_idx]) for class_idx in range(num_classes)]\n",
    "# Print the number of training images for each class (expected ~100,000 per class)\n",
    "print(\"Original training images per class:\", T_per_class)\n",
    "\n",
    "# Get validation dataset details\n",
    "val_targets = val_dataset.targets  # Extract list of class labels for validation images\n",
    "# Create dictionary mapping each class index to indices of images belonging to that class\n",
    "val_class_indices = {\n",
    "    class_idx: [i for i, t in enumerate(val_targets) if t == class_idx]\n",
    "    for class_idx in range(num_classes)\n",
    "}\n",
    "# Calculate number of validation images per class\n",
    "V_per_class = [len(val_class_indices[class_idx]) for class_idx in range(num_classes)]\n",
    "# Print the number of validation images for each class (size may vary)\n",
    "print(\"Original validation images per class:\", V_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T14:33:47.921125Z",
     "iopub.status.busy": "2025-04-08T14:33:47.920824Z",
     "iopub.status.idle": "2025-04-08T14:42:44.532012Z",
     "shell.execute_reply": "2025-04-08T14:42:44.531162Z",
     "shell.execute_reply.started": "2025-04-08T14:33:47.921104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the training dataset using ImageFolder, applying the transformation defined for training data\n",
    "train_dataset = ImageFolder(root='path_to/poultry-diseases/data/data/train', transform=train_transform)\n",
    "\n",
    "# Get the class labels (targets) from the training dataset\n",
    "targets = train_dataset.targets\n",
    "\n",
    "# Create a dictionary where the key is the class index and the value is a list of image indices for that class\n",
    "class_indices = {class_idx: [i for i, t in enumerate(targets) if t == class_idx] for class_idx in range(num_classes)}\n",
    "\n",
    "# Initialize an empty list to store the indices of the sampled images\n",
    "sampled_indices = []\n",
    "\n",
    "# For each class, sample a specified number of images (10000 in this case, but adjust according to your needs)\n",
    "for class_idx in range(num_classes):\n",
    "    class_idx_list = class_indices[class_idx]\n",
    "    sampled = random.sample(class_idx_list, 10000)  # Sample 10000 images per class for the first iteration\n",
    "    sampled_indices.extend(sampled)  # Add the sampled indices to the list\n",
    "\n",
    "# Create a subset of the training dataset using the sampled indices, to ensure only the sampled images are used\n",
    "train_subset = Subset(train_dataset, sampled_indices)\n",
    "\n",
    "# Load the validation dataset (using the full test set as validation data here)\n",
    "val_dataset = ImageFolder(root='path_to/poultry-diseases/data/data/test', transform=val_transform)\n",
    "\n",
    "# Define the batch size for training and validation\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader for the training subset, which will load the training data in batches, shuffle, and use multiple workers\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Create a DataLoader for the validation dataset, which will load the validation data in batches without shuffling\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T14:42:57.265746Z",
     "iopub.status.busy": "2025-04-08T14:42:57.265442Z",
     "iopub.status.idle": "2025-04-08T14:42:57.327166Z",
     "shell.execute_reply": "2025-04-08T14:42:57.326505Z",
     "shell.execute_reply.started": "2025-04-08T14:42:57.265721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subset images per class:\n",
      "Class 0: 10000\n",
      "Class 1: 10000\n",
      "Class 2: 10000\n",
      "Class 3: 10000\n"
     ]
    }
   ],
   "source": [
    "# Number of sampled images per class for training\n",
    "t = 10000\n",
    "\n",
    "# Initialize an empty list to store the indices of the sampled images for training\n",
    "train_sampled_indices = []\n",
    "\n",
    "# Loop through each class index (from 0 to num_classes - 1)\n",
    "for class_idx in range(num_classes):\n",
    "    # Randomly sample 't' images from the indices of the current class\n",
    "    sampled = random.sample(train_class_indices[class_idx], t)\n",
    "    # Add the sampled indices to the list of training sampled indices\n",
    "    train_sampled_indices.extend(sampled)\n",
    "\n",
    "# Create a subset of the training dataset containing only the sampled indices\n",
    "train_subset = Subset(train_dataset, train_sampled_indices)\n",
    "\n",
    "# Verify the number of images per class in the training subset\n",
    "print(\"Training subset images per class:\")\n",
    "for class_idx in range(num_classes):\n",
    "    # Count the number of images in train_sampled_indices belonging to the current class\n",
    "    count = len([i for i in train_sampled_indices if train_targets[i] == class_idx])\n",
    "    print(f\"Class {class_idx}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T14:43:02.729673Z",
     "iopub.status.busy": "2025-04-08T14:43:02.729391Z",
     "iopub.status.idle": "2025-04-08T14:43:02.750570Z",
     "shell.execute_reply": "2025-04-08T14:43:02.749744Z",
     "shell.execute_reply.started": "2025-04-08T14:43:02.729653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation subset images per class:\n",
      "Class 0: 1875\n",
      "Class 1: 1741\n",
      "Class 2: 1588\n",
      "Class 3: 1862\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the indices of the sampled images for validation\n",
    "val_sampled_indices = []\n",
    "\n",
    "# Loop through each class index (from 0 to num_classes - 1)\n",
    "for class_idx in range(num_classes):\n",
    "    # Calculate the proportion of images to sample for this class based on the total number of images 't'\n",
    "    proportion = t / T_per_class[class_idx]  # e.g., 2500 / 100000 = 0.025\n",
    "    \n",
    "    # Calculate the number of images to sample for this class based on its proportion\n",
    "    v = int(V_per_class[class_idx] * proportion)  # Number to sample\n",
    "    \n",
    "    # If the calculated number of images to sample exceeds the available images, cap it\n",
    "    if v > V_per_class[class_idx]:\n",
    "        v = V_per_class[class_idx]\n",
    "    # Ensure that at least one image is sampled for each class\n",
    "    elif v < 1:\n",
    "        v = 1\n",
    "    \n",
    "    # Randomly sample 'v' images from the indices of the current class\n",
    "    sampled = random.sample(val_class_indices[class_idx], v)\n",
    "    \n",
    "    # Add the sampled indices to the list of validation sampled indices\n",
    "    val_sampled_indices.extend(sampled)\n",
    "\n",
    "# Create a subset of the validation dataset containing only the sampled indices\n",
    "val_subset = Subset(val_dataset, val_sampled_indices)\n",
    "\n",
    "# Verify the number of images per class in the validation subset\n",
    "print(\"Validation subset images per class:\")\n",
    "for class_idx in range(num_classes):\n",
    "    # Count the number of images in val_sampled_indices belonging to the current class\n",
    "    count = len([i for i in val_sampled_indices if val_targets[i] == class_idx])\n",
    "    print(f\"Class {class_idx}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:05:11.505000Z",
     "iopub.status.busy": "2025-04-08T11:05:11.504709Z",
     "iopub.status.idle": "2025-04-08T11:05:11.509143Z",
     "shell.execute_reply": "2025-04-08T11:05:11.508323Z",
     "shell.execute_reply.started": "2025-04-08T11:05:11.504978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the batch size for training and validation\n",
    "batch_size = 32  # You can adjust this depending on your system's memory capacity\n",
    "\n",
    "# Create a DataLoader for the training subset\n",
    "train_loader = DataLoader(\n",
    "    train_subset,  # The training data subset containing the sampled images\n",
    "    batch_size=batch_size,  # Number of samples per batch\n",
    "    shuffle=True,  # Shuffle the data at the start of each epoch to improve generalization\n",
    "    num_workers=2,  # Number of subprocesses to load the data (adjust based on your machine's capabilities)\n",
    "    pin_memory=True  # Pin the data in memory to speed up the transfer to GPU (if using a GPU)\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the validation subset\n",
    "val_loader = DataLoader(\n",
    "    val_subset,  # The validation data subset containing the sampled images\n",
    "    batch_size=batch_size,  # Number of samples per batch\n",
    "    shuffle=False,  # Do not shuffle validation data as it's not necessary for evaluation\n",
    "    num_workers=2,  # Number of subprocesses to load the data\n",
    "    pin_memory=True  # Pin the data in memory to speed up the transfer to GPU\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T11:05:14.336183Z",
     "iopub.status.busy": "2025-04-08T11:05:14.335883Z",
     "iopub.status.idle": "2025-04-08T11:05:14.344123Z",
     "shell.execute_reply": "2025-04-08T11:05:14.343322Z",
     "shell.execute_reply.started": "2025-04-08T11:05:14.336161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss function: CrossEntropyLoss for multi-class classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Import necessary components for mixed precision training\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Initialize a GradScaler to help with mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training function\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0  # Initialize running loss\n",
    "\n",
    "    # Loop through the training data in batches\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data and target to the device (GPU/CPU)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        with autocast('cuda'):  # Enable mixed precision for faster computation on GPUs\n",
    "            output = model(data)  # Forward pass through the model\n",
    "            loss = criterion(output, target)  # Compute the loss\n",
    "\n",
    "        # Scale the loss and backpropagate\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Update model parameters with gradient scaling\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()  # Accumulate the loss for monitoring\n",
    "    # Return average loss for the epoch\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "# Evaluation function (for validation or test set)\n",
    "def evaluate(model, device, val_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    val_loss = 0.0  # Initialize validation loss\n",
    "    correct = 0  # Initialize correct predictions counter\n",
    "    total = 0  # Initialize total number of samples\n",
    "\n",
    "    # No gradients needed during evaluation\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)  # Move data and target to the device\n",
    "\n",
    "            output = model(data)  # Forward pass through the model\n",
    "            val_loss += criterion(output, target).item()  # Compute the loss\n",
    "\n",
    "            # Get the predicted class for each sample\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()  # Count correct predictions\n",
    "            total += target.size(0)  # Count total samples\n",
    "\n",
    "    # Compute the average validation loss\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    # Calculate accuracy as a percentage\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Return validation loss and accuracy\n",
    "    return val_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T14:43:10.260453Z",
     "iopub.status.busy": "2025-04-08T14:43:10.260125Z",
     "iopub.status.idle": "2025-04-08T16:48:02.086874Z",
     "shell.execute_reply": "2025-04-08T16:48:02.085792Z",
     "shell.execute_reply.started": "2025-04-08T14:43:10.260427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1, Epoch 1: Train Loss: 0.3497, Val Loss: 0.2797, Val Accuracy: 89.72%\n",
      "Stage 1, Epoch 2: Train Loss: 0.3466, Val Loss: 0.2790, Val Accuracy: 89.83%\n",
      "Stage 1, Epoch 3: Train Loss: 0.3426, Val Loss: 0.2784, Val Accuracy: 89.82%\n",
      "Stage 1, Epoch 4: Train Loss: 0.3427, Val Loss: 0.2782, Val Accuracy: 89.86%\n",
      "Stage 1, Epoch 5: Train Loss: 0.3423, Val Loss: 0.2790, Val Accuracy: 89.81%\n",
      "Stage 1, Epoch 6: Train Loss: 0.3392, Val Loss: 0.2774, Val Accuracy: 89.91%\n",
      "Stage 1, Epoch 7: Train Loss: 0.3452, Val Loss: 0.2780, Val Accuracy: 89.85%\n",
      "Stage 1, Epoch 8: Train Loss: 0.3402, Val Loss: 0.2785, Val Accuracy: 89.82%\n",
      "Stage 1, Epoch 9: Train Loss: 0.3459, Val Loss: 0.2783, Val Accuracy: 89.82%\n",
      "Stage 1, Epoch 10: Train Loss: 0.3410, Val Loss: 0.2775, Val Accuracy: 89.85%\n",
      "Stage 1, Epoch 11: Train Loss: 0.3364, Val Loss: 0.2785, Val Accuracy: 89.85%\n",
      "Stage 1, Epoch 12: Train Loss: 0.3401, Val Loss: 0.2776, Val Accuracy: 89.85%\n",
      "Stage 1, Epoch 13: Train Loss: 0.3346, Val Loss: 0.2786, Val Accuracy: 89.83%\n",
      "Stage 1, Epoch 14: Train Loss: 0.3372, Val Loss: 0.2773, Val Accuracy: 89.80%\n",
      "Stage 1, Epoch 15: Train Loss: 0.3404, Val Loss: 0.2774, Val Accuracy: 89.88%\n",
      "Stage 1, Epoch 16: Train Loss: 0.3368, Val Loss: 0.2774, Val Accuracy: 89.82%\n",
      "Stage 1, Epoch 17: Train Loss: 0.3386, Val Loss: 0.2773, Val Accuracy: 89.86%\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: Train only the classifier (freeze other layers)\n",
    "# Freeze all layers in the model by setting 'requires_grad' to False\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Enable gradient computation for the fully connected (classifier) layer\n",
    "for param in model._fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Use the AdamW optimizer to train only the classifier with a small learning rate\n",
    "optimizer = torch.optim.AdamW(model._fc.parameters(), lr=0.0001)\n",
    "\n",
    "# Loop through the epochs for training and validation\n",
    "for epoch in range(1, 18):  # Training for 17 epochs (1 to 17)\n",
    "    # Train the model on the current epoch\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = evaluate(model, device, val_loader, criterion)\n",
    "    \n",
    "    # Print the training and validation results for the current epoch\n",
    "    print(f'Stage 1, Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T16:49:12.600210Z",
     "iopub.status.busy": "2025-04-08T16:49:12.599916Z",
     "iopub.status.idle": "2025-04-08T19:01:17.150953Z",
     "shell.execute_reply": "2025-04-08T19:01:17.149954Z",
     "shell.execute_reply.started": "2025-04-08T16:49:12.600189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2, Epoch 1: Train Loss: 0.3317, Val Loss: 0.2703, Val Accuracy: 90.07%\n",
      "Stage 2, Epoch 2: Train Loss: 0.3291, Val Loss: 0.2642, Val Accuracy: 90.29%\n",
      "Stage 2, Epoch 3: Train Loss: 0.3156, Val Loss: 0.2590, Val Accuracy: 90.52%\n",
      "Stage 2, Epoch 4: Train Loss: 0.3079, Val Loss: 0.2530, Val Accuracy: 90.74%\n",
      "Stage 2, Epoch 5: Train Loss: 0.2981, Val Loss: 0.2497, Val Accuracy: 90.87%\n",
      "Stage 2, Epoch 6: Train Loss: 0.2943, Val Loss: 0.2447, Val Accuracy: 91.01%\n",
      "Stage 2, Epoch 7: Train Loss: 0.2833, Val Loss: 0.2401, Val Accuracy: 91.16%\n",
      "Stage 2, Epoch 8: Train Loss: 0.2823, Val Loss: 0.2367, Val Accuracy: 91.32%\n",
      "Stage 2, Epoch 9: Train Loss: 0.2769, Val Loss: 0.2331, Val Accuracy: 91.46%\n",
      "Stage 2, Epoch 10: Train Loss: 0.2705, Val Loss: 0.2294, Val Accuracy: 91.59%\n",
      "Training complete. Best validation accuracy: 91.59%\n"
     ]
    }
   ],
   "source": [
    "# Stage 2: Fine-tune the entire model (unfreeze all layers)\n",
    "# Unfreeze all layers by setting 'requires_grad' to True\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Use the SGD optimizer with a smaller learning rate and momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.8496)\n",
    "\n",
    "# Initialize variable to track the best validation accuracy\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Loop through the epochs for training and validation\n",
    "for epoch in range(1, 11):  # Fine-tuning for 10 epochs (1 to 10)\n",
    "    # Train the model on the current epoch\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = evaluate(model, device, val_loader, criterion)\n",
    "    \n",
    "    # Print the training and validation results for the current epoch\n",
    "    print(f'Stage 2, Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # If the current validation accuracy is better than the best seen so far, save the model\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Print the final result\n",
    "print(f\"Training complete. Best validation accuracy: {best_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load your trained model\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device, weights_only=True))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# 2. Create a data loader for your validation/test set\n",
    "# (we are using the above subset of validation/test dataset)\n",
    "\n",
    "# 3. Run inference on validation/test data\n",
    "all_preds = []\n",
    "all_probs = []  # For storing probability outputs\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in val_loader:  # Use your validation or test dataloader\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predicted class\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Get probabilities\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_targets.extend(targets.numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.vstack(all_probs)  # Stack all probability outputs\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# 4. Calculate metrics\n",
    "# F1 score (macro - unweighted average across classes)\n",
    "f1_macro = f1_score(all_targets, all_preds, average='macro')\n",
    "# F1 score (weighted by support - number of true instances for each class)\n",
    "f1_weighted = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "# Calculate per-class precision, recall, F1\n",
    "precision, recall, f1_per_class, support = precision_recall_fscore_support(all_targets, all_preds)\n",
    "\n",
    "# 5. Calculate mAP (Mean Average Precision)\n",
    "# For multi-class problems, calculate AP for each class and then average\n",
    "num_classes = all_probs.shape[1]\n",
    "average_precisions = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    # Create binary labels for this class (one-vs-rest approach)\n",
    "    binary_targets = (all_targets == i).astype(int)\n",
    "    # Get predicted probabilities for this class\n",
    "    class_probs = all_probs[:, i]\n",
    "    # Calculate average precision\n",
    "    ap = average_precision_score(binary_targets, class_probs)\n",
    "    average_precisions.append(ap)\n",
    "\n",
    "# Calculate mAP\n",
    "mAP = np.mean(average_precisions)\n",
    "\n",
    "# 6. Print results\n",
    "print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
    "print(f\"mAP Score: {mAP:.4f}\")\n",
    "\n",
    "# 7. Print per-class metrics\n",
    "class_names = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']  # Replace with your actual class names\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"{class_names[i]}: Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1_per_class[i]:.4f}, Support: {support[i]}\")\n",
    "\n",
    "# 8. Generate confusion matrix\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "# 9. Calculate FLOPs\n",
    "# Get a sample input from train_loader (adjust shape as needed)\n",
    "sample_input, _ = next(iter(train_loader))\n",
    "sample_input = sample_input.to(device)\n",
    "\n",
    "# Profile the forward pass FLOPs (multiply-add operations)\n",
    "flops_forward, _ = profile(model, inputs=(sample_input[:1],))  # Use batch size 1 for simplicity\n",
    "\n",
    "# Estimate FLOPs per training step (forward + backward)\n",
    "flops_per_train_step = 2 * flops_forward  # Backward pass ≈ forward pass\n",
    "\n",
    "# Total FLOPs for training (5 epochs)\n",
    "num_train_steps = len(train_loader)\n",
    "num_val_steps = len(val_loader)\n",
    "total_train_flops = 5 * num_train_steps * flops_per_train_step\n",
    "\n",
    "# Total FLOPs for evaluation (5 epochs)\n",
    "total_val_flops = 5 * num_val_steps * flops_forward\n",
    "\n",
    "# Total FLOPs for the snippet\n",
    "total_flops = total_train_flops + total_val_flops\n",
    "\n",
    "print(f\"Total FLOPs: {total_flops:.2e}\")\n",
    "\n",
    "total_tflops = total_flops / 1e12\n",
    "print(f\"Total TFLOPs: {total_tflops:.4f}\")\n",
    "\n",
    "# 10. Calculate Inference Speed\n",
    "# Optional: Warm up the model to mitigate any initial overhead\n",
    "with torch.no_grad():\n",
    "    _ = model(sample_input[:1])\n",
    "\n",
    "total_inference_time = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in val_loader:\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        start_time = time.time()\n",
    "        _ = model(images)\n",
    "        batch_time = time.time() - start_time\n",
    "        total_inference_time += batch_time\n",
    "        total_samples += batch_size\n",
    "\n",
    "# Compute average inference time per sample\n",
    "avg_inference_time_per_sample = total_inference_time / total_samples\n",
    "print(f\"Average inference time per sample: {avg_inference_time_per_sample:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained EfficientNet B3\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3').to(device)\n",
    "model._fc = nn.Linear(model._fc.in_features, num_classes).to(device)\n",
    "model_path = 'best_model.pth'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval() # Set to evaluation mode\n",
    "#  Calculate FLOPs\n",
    "# Get a sample input from train_loader (adjust shape as needed)\n",
    "sample_input, _ = next(iter(train_loader))\n",
    "sample_input = sample_input.to(device)\n",
    "\n",
    "# Profile the forward pass FLOPs (multiply-add operations)\n",
    "flops_forward, _ = profile(model, inputs=(sample_input[:1],))  # Use batch size 1 for simplicity\n",
    "\n",
    "# Stage 1: Classifier only (17 epochs)\n",
    "# For classifier-only training, we need separate profiling since only classifier is active\n",
    "# First, set all parameters to not require gradients except classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model._fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Profile classifier-only forward pass\n",
    "flops_forward_classifier_only, _ = profile(model, inputs=(sample_input[:1],))\n",
    "\n",
    "# Estimate FLOPs per training step for classifier-only training\n",
    "# Backward pass cost will be much lower since we're only computing gradients for classifier\n",
    "flops_per_train_step_classifier = flops_forward_classifier_only + (flops_forward_classifier_only * 0.05)  # Approximate backward pass cost\n",
    "\n",
    "# Stage 2: Full model (10 epochs)\n",
    "# Reset all parameters to require gradients\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Estimate FLOPs per training step for full model training\n",
    "flops_per_train_step_full = flops_forward * 2  # Backward pass ≈ forward pass for full model\n",
    "\n",
    "# Calculate total FLOPs for both stages (per iteration)\n",
    "num_train_steps = len(train_loader)\n",
    "num_val_steps = len(val_loader)\n",
    "\n",
    "# Stage 1: 17 epochs of classifier-only training\n",
    "num_epochs_stage1 = 17\n",
    "total_train_flops_stage1 = num_epochs_stage1 * num_train_steps * flops_per_train_step_classifier\n",
    "total_val_flops_stage1 = num_epochs_stage1 * num_val_steps * flops_forward\n",
    "\n",
    "# Stage 2: 10 epochs of full model training\n",
    "num_epochs_stage2 = 10\n",
    "total_train_flops_stage2 = num_epochs_stage2 * num_train_steps * flops_per_train_step_full\n",
    "total_val_flops_stage2 = num_epochs_stage2 * num_val_steps * flops_forward\n",
    "\n",
    "# Total FLOPs for one complete iteration (Stage 1 + Stage 2)\n",
    "total_flops_per_iteration = (total_train_flops_stage1 + total_val_flops_stage1 +\n",
    "                            total_train_flops_stage2 + total_val_flops_stage2)\n",
    "\n",
    "# Total FLOPs for all iterations\n",
    "num_iterations = 3  # Original + 2 more iterations = 3 total\n",
    "total_flops = num_iterations * total_flops_per_iteration\n",
    "\n",
    "print(f\"FLOPs per iteration (Stage 1 + Stage 2): {total_flops_per_iteration:.2e}\")\n",
    "print(f\"Total FLOPs for {num_iterations} iterations: {total_flops:.2e}\")\n",
    "\n",
    "total_tflops = total_flops / 1e12\n",
    "print(f\"Total TFLOPs: {total_tflops:.4f}\")\n",
    "\n",
    "# Breakdown by stage and iteration\n",
    "total_train_flops_stage1_all = num_iterations * total_train_flops_stage1\n",
    "total_train_flops_stage2_all = num_iterations * total_train_flops_stage2\n",
    "total_train_tflops_stage1 = total_train_flops_stage1_all / 1e12\n",
    "total_train_tflops_stage2 = total_train_flops_stage2_all / 1e12\n",
    "\n",
    "print(f\"Stage 1 (Classifier) training TFLOPs ({num_iterations} iterations): {total_train_tflops_stage1:.4f}\")\n",
    "print(f\"Stage 2 (Full model) training TFLOPs ({num_iterations} iterations): {total_train_tflops_stage2:.4f}\")\n",
    "print(f\"Combined training TFLOPs ({num_iterations} iterations): {(total_train_tflops_stage1 + total_train_tflops_stage2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Log Summary\n",
    "\n",
    "## Iteration 1\n",
    "### Stage 1\n",
    "\n",
    "| Epoch | Train Loss | Val Loss | Val Accuracy |\n",
    "|-------|------------|----------|-------------|\n",
    "| 1     | 1.2405     | 1.0812   | 68.67%      |\n",
    "| 2     | 1.0297     | 0.9346   | 70.76%      |\n",
    "| 3     | 0.9250     | 0.8526   | 71.78%      |\n",
    "| 4     | 0.8644     | 0.8003   | 73.14%      |\n",
    "| 5     | 0.8236     | 0.7646   | 74.16%      |\n",
    "| 6     | 0.7912     | 0.7384   | 74.50%      |\n",
    "| 7     | 0.7747     | 0.7171   | 75.07%      |\n",
    "| 8     | 0.7557     | 0.7012   | 75.35%      |\n",
    "| 9     | 0.7486     | 0.6900   | 76.03%      |\n",
    "| 10    | 0.7248     | 0.6788   | 75.86%      |\n",
    "| 11    | 0.7291     | 0.6698   | 75.98%      |\n",
    "| 12    | 0.7120     | 0.6636   | 75.86%      |\n",
    "| 13    | 0.7082     | 0.6560   | 75.98%      |\n",
    "| 14    | 0.7063     | 0.6507   | 76.20%      |\n",
    "| 15    | 0.6973     | 0.6465   | 76.54%      |\n",
    "| 16    | 0.6969     | 0.6404   | 76.37%      |\n",
    "| 17    | 0.6843     | 0.6380   | 76.49%      |\n",
    "\n",
    "### Stage 2\n",
    "\n",
    "| Epoch | Train Loss | Val Loss | Val Accuracy |\n",
    "|-------|------------|----------|-------------|\n",
    "| 1     | 0.6763     | 0.6054   | 77.85%      |\n",
    "| 2     | 0.6431     | 0.5789   | 78.92%      |\n",
    "| 3     | 0.6226     | 0.5537   | 79.77%      |\n",
    "| 4     | 0.5870     | 0.5331   | 79.89%      |\n",
    "| 5     | 0.5710     | 0.5161   | 80.45%      |\n",
    "| 6     | 0.5565     | 0.5019   | 81.08%      |\n",
    "| 7     | 0.5241     | 0.4871   | 81.76%      |\n",
    "| 8     | 0.5173     | 0.4745   | 82.44%      |\n",
    "| 9     | 0.5096     | 0.4623   | 82.21%      |\n",
    "| 10    | 0.4844     | 0.4533   | 82.44%      |\n",
    "\n",
    "**Best validation accuracy: 82.44%**\n",
    "\n",
    "## Iteration 2\n",
    "### Stage 1\n",
    "\n",
    "| Epoch | Train Loss | Val Loss | Val Accuracy |\n",
    "|-------|------------|----------|-------------|\n",
    "| 1     | 0.5280     | 0.4486   | 83.92%      |\n",
    "| 2     | 0.5166     | 0.4442   | 84.01%      |\n",
    "| 3     | 0.5107     | 0.4411   | 84.09%      |\n",
    "| 4     | 0.5071     | 0.4371   | 84.18%      |\n",
    "| 5     | 0.5045     | 0.4346   | 84.04%      |\n",
    "| 6     | 0.5032     | 0.4352   | 83.99%      |\n",
    "| 7     | 0.5011     | 0.4327   | 84.15%      |\n",
    "| 8     | 0.4982     | 0.4298   | 84.32%      |\n",
    "| 9     | 0.4984     | 0.4282   | 84.38%      |\n",
    "| 10    | 0.4981     | 0.4276   | 84.42%      |\n",
    "| 11    | 0.4985     | 0.4279   | 84.49%      |\n",
    "| 12    | 0.4981     | 0.4273   | 84.50%      |\n",
    "| 13    | 0.4947     | 0.4254   | 84.66%      |\n",
    "| 14    | 0.4943     | 0.4249   | 84.67%      |\n",
    "| 15    | 0.4935     | 0.4216   | 84.67%      |\n",
    "| 16    | 0.4945     | 0.4225   | 84.45%      |\n",
    "| 17    | 0.4936     | 0.4224   | 84.31%      |\n",
    "\n",
    "### Stage 2\n",
    "\n",
    "| Epoch | Train Loss | Val Loss | Val Accuracy |\n",
    "|-------|------------|----------|-------------|\n",
    "| 1     | 0.4783     | 0.3891   | 85.79%      |\n",
    "| 2     | 0.4450     | 0.3650   | 86.54%      |\n",
    "| 3     | 0.4213     | 0.3470   | 87.22%      |\n",
    "| 4     | 0.3990     | 0.3333   | 87.73%      |\n",
    "| 5     | 0.3849     | 0.3183   | 88.30%      |\n",
    "| 6     | 0.3702     | 0.3091   | 88.72%      |\n",
    "| 7     | 0.3550     | 0.2983   | 89.03%      |\n",
    "| 8     | 0.3481     | 0.2901   | 89.27%      |\n",
    "| 9     | 0.3330     | 0.2826   | 89.53%      |\n",
    "| 10    | 0.3278     | 0.2757   | 89.74%      |\n",
    "\n",
    "**Best validation accuracy: 89.74%**\n",
    "\n",
    "## Iteration 3\n",
    "### Stage 1\n",
    "\n",
    "| Epoch | Train Loss | Val Loss | Val Accuracy |\n",
    "|-------|------------|----------|-------------|\n",
    "| 1     | 0.3497     | 0.2797   | 89.72%      |\n",
    "| 2     | 0.3466     | 0.2790   | 89.83%      |\n",
    "| 3     | 0.3426     | 0.2784   | 89.82%      |\n",
    "| 4     | 0.3427     | 0.2782   | 89.86%      |\n",
    "| 5     | 0.3423     | 0.2790   | 89.81%      |\n",
    "| 6     | 0.3392     | 0.2774   | 89.91%      |\n",
    "| 7     | 0.3452     | 0.2780   | 89.85%      |\n",
    "| 8     | 0.3402     | 0.2785   | 89.82%      |\n",
    "| 9     | 0.3459     | 0.2783   | 89.82%      |\n",
    "| 10    | 0.3410     | 0.2775   | 89.85%      |\n",
    "| 11    | 0.3364     | 0.2785   | 89.85%      |\n",
    "| 12    | 0.3401     | 0.2776   | 89.85%      |\n",
    "| 13    | 0.3346     | 0.2786   | 89.83%      |\n",
    "| 14    | 0.3372     | 0.2773   | 89.80%      |\n",
    "| 15    | 0.3404     | 0.2774   | 89.88%      |\n",
    "| 16    | 0.3368     | 0.2774   | 89.82%      |\n",
    "| 17    | 0.3386     | 0.2773   | 89.86%      |\n",
    "\n",
    "### Stage 2\n",
    "\n",
    "| Epoch | Train Loss | Val Loss | Val Accuracy |\n",
    "|-------|------------|----------|-------------|\n",
    "| 1     | 0.2765     | 0.1854   | 93.15%      |\n",
    "| 2     | 0.1544     | 0.1546   | 94.51%      |\n",
    "| 3     | 0.1023     | 0.1485   | 95.09%      |\n",
    "| 4     | 0.0720     | 0.1415   | 95.08%      |\n",
    "| 5     | 0.0564     | 0.1552   | 95.09%      |\n",
    "| 6     | 0.0431     | 0.1788   | 94.88%      |\n",
    "| 7     | 0.0389     | 0.1643   | 94.92%      |\n",
    "| 8     | 0.0297     | 0.1760   | 95.29%      |\n",
    "| 9     | 0.0285     | 0.1839   | 95.16%      |\n",
    "| 10    | 0.0277     | 0.1729   | 95.56%      |\n",
    "\n",
    "**Best validation accuracy: 95.56%**\n",
    "\n",
    "### Progress Summary\n",
    "\n",
    "| Iteration | Final Val Accuracy | Improvement |\n",
    "|-----------|-------------------|-------------|\n",
    "| 1         | 82.44%            | -           |\n",
    "| 2         | 89.74%            | +7.30%      |\n",
    "| 3         | 95.56%            | +5.62%      |"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3951043,
     "sourceId": 6934176,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
